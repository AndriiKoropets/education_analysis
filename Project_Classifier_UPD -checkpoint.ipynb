{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Завадання від Мар'яни\n",
    "1. підключи якусь NLP бібліотеку, що працює з німецькою мовою (таких є достатньо, включно зі spaCy  - в нас вже є spaCy\n",
    "2. сформувати вектор статті і міряти з кожним коментарем окремо (взяти сутності зі статті та порівняти сутності з коментарями)\n",
    "3. зроби токенізацію і лематизацію з бібліотекою - використай леми, а не словоформи, як фічі\n",
    "4. виділи іменовані сутності (типу Kiew, Ukraine) і відфільтруй\n",
    "5. для порівняння результатів з логістичної регресії  спробувати SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Завдання 1\n",
    "Підключаємо спейсі, модель `de_core_news_md` вже містить 20к векторів слів (розмірності 300), тому нічого додатково завантажувати не потрібно. Хоча для подальших експериментів можна додати більш повні вектори або ж натренувати свої на статтях з відповідних журналів"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('de_core_news_md')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from dataframe import DataFrame\n",
    "from readers import read_comments, read_article"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Приклад\n",
    "для першого слова вектор є, але для другого немає - всі нулі"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, array([-0.350431,  0.294666,  0.293048, -0.212729, -0.398173,  0.530178,\n",
       "        -0.069264,  0.305221,  0.085919, -0.29125 ], dtype=float32))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp('organisierten')[0].has_vector, nlp('organisierten')[0].vector[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(False, array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp('Maidan')[0].has_vector, nlp('Maidan')[0].vector[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Завдання 2\n",
    "Порахуємо відстань між векторами коментарів та статті, у спейсі документ та спан також мають всій вектор - це середнє арифметичне векторів всіх токенів, для першого наближення згодиться."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "work_dir = Path()\n",
    "\n",
    "comments = read_comments(work_dir / 'die Revolution in Kiew_comments.txt')\n",
    "article = read_article(work_dir / 'die Revolution in Kiew_article.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label': 'neutral',\n",
       " 'author': 'Baudrillard',\n",
       " 'text': '\"Die Ukraine ist das gro?te Land Europas\".Lieber Herr Dobbert, eigentlich ist Russland das Gro?te Land Europas, mit einer Flache von 3,9 Mio.Quadratkilometern'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sieben Irrtumer uber die Revolution in Kiew\n",
      "Der Prasident der Ukraine hat sich ein Problem geschaffen, dessen er ohne Amtsverlust wohl nicht mehr Herr wird. Wie und durch wen es wirklich zum Volksaufstand kam.\n",
      "Von Steffen Dobbert\n",
      "Viktor Janukowitsch sieht gerade zu, wie viele Burger seines Landes Revolutionsgeschichte schreiben. Im Mittelpunkt steht er, der zum zweiten Mal ein sicher geglaubtes Prasidentenamt verlieren konnte. Momentan deutet vieles darauf hin, dass der Aufstand endet wie 2004 bei der Orangenen Revolution. Die Mehrheit des Volkes wird nicht aufhoren zu protestieren,\n"
     ]
    }
   ],
   "source": [
    "article = nlp(article)\n",
    "print(article[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# косинусна відстань між векторами\n",
    "def similarity(doc1, doc2):\n",
    "    return np.dot(doc1.vector, doc2.vector) / (np.linalg.norm(doc1.vector) * np.linalg.norm(doc2.vector))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# порахуємо відстань між статтею та усіма векторами\n",
    "dists = list()\n",
    "for com in comments:\n",
    "    cdoc = nlp(com['text'])\n",
    "    dists.append(similarity(cdoc, article))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# індекси посортовані по значенню відстані\n",
    "arg_dists = np.argsort(dists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min-dist=0.61, Max-dist=0.99\n"
     ]
    }
   ],
   "source": [
    "# пояснення\n",
    "print(f'Min-dist={dists[arg_dists[0]]:.2f}, Max-dist={dists[arg_dists[-1]]:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** топ 3 найвіддаленіших коментарів ***\n",
      "{'label': 'neutral', 'author': 'norbertZ', 'text': 'Klasse Artikel, Herr Dobbert Danke.'}\n",
      "{'label': 'neutral', 'author': 'Baudrillard', 'text': '\"Die Ukraine ist das gro?te Land Europas\".Lieber Herr Dobbert, eigentlich ist Russland das Gro?te Land Europas, mit einer Flache von 3,9 Mio.Quadratkilometern'}\n",
      "{'label': 'neutral', 'author': 'Dichter als Goethe', 'text': 'nur 95% sachlich und 80% differenziert. Fehler des Artikelverfassers (imho) zeige ich im anderen Kommentar.'}\n",
      "\n",
      "\n",
      " *** топ 3 найближчих кометарів ***\n",
      "{'label': 'neutral', 'author': 'lxththf', 'text': 'Oligarchen. \"Von der EU haben die Ukrainer kaum Unterstutzung bekommen.\"Ich lege meine Hand dafur ins Feuer, dass das nicht stimmt! Wer wen bei was wie wo unterstutzt ist in den meisten Fallen nicht nachweisbar. Wen man jedoch 1 + 1 zusammenzahlt, kommt man von selbst drauf. Man stelle sich nur die Frage: Wem nutzt es?\"Doch vermutlich steckt hinter dem Einlenken auch der Einfluss der ukrainischen Oligarchen.\"Mir scheint es ist die Oligarchie die auf der Welt regiert und bestimmt.Aber neee, ist ja nur eine\\'Verschworungstheorie\\'\"Nichtstaatliche TV-Sender der Ukraine, die im Besitz anderer Oligarchen sind, berichten kritisch uber das gewaltsame Vorgehen der Sondereinsatzpolizisten.\"Ist leider auch in Deutschland so, dass sich Menschen von allem moglichen Bockmist im TV beeinflussen lassen. Da werden Kampagnen verbreitet nur mit dem einen Ziel, die Gesinnung der Bevolkerung in eine bestimmte Richtung zu lenken, die Leute glauben der Glotze mehr als dem eigenen Verstand.'}\n",
      "{'label': 'neutral', 'author': 'Anzugveraechter', 'text': 'Lenkt die Presse nun langsam ein?Einen Artikel wie den obigen, der einfach mal differenziert darstellt, wer sich das in Kiew gegenubersteht, hatte man sich schon vor Wochen gewunscht; nun ist das leider nichts Neues mehr, da sich die meisten Leser diese Informationen bereits aus dem Netz zusammengesucht und im Forum hier ausfuhrlich dargestellt haben. In diesem Sinne kommt er m.E. genauso zu spat wie das Einlenken Janukowitschs.Es bleiben Fragen die personliche Bereicherung des Prasidenten und seiner Familie.Der Wahlbetrug.Die Korruption.Die schwache Okonomie des Landes, die doch schon langer bekannt waren, keine Hinderungsgrunde fur die EU, bis November mit Janukowitsch zu verhandeln?Diese Verhandlungen, korrigieren Sie mich, wenn ich falsch liege! - hatten doch sicher nicht die Absicht, die Macht der Oligarchen zu begrenzen. Und es klingt auch heute noch so, als kame man an den Oligarchen nicht vorbei.Hei?t das, dass man die Oligarchen und deren (nun kunftige) Marionetten immer noch als ernsthafte Verhandlungspartner der EU betrachtet?Ich sehe gerade im Gebaren der Oligarchen einen der Hauptgrunde fur die Armut und das Untergraben der Demokratie in der Ukraine bleibe daher au?erst skeptisch.'}\n",
      "{'label': 'trolling', 'author': 'faktenfaktenfakten', 'text': 'nicht weil der Artikel positiv fuer die Menschen vom Maidan waere sondern weil er eine ganze Reihe an Hintergrundwissen bietet, welches leider kaum in der Lage ist mit spektakulaeren Fotos zu konkurieren. Und doch eine kleine Verbesserung: In Ihrem Beitrag kllingt es ein Wenig, als sei die Radikalisierung des Protestes mehr zufaellig durch die Aktivierung des Rechten Fluegels (der explizit sich von Svoboda abgrenzt) ausgegangen. Den Dezember hindurch war der Protest absolut friedlich, es herrschte jedoch eine extrem angespannte Ruhe, da eine ganze Reihe von Regierungsgegnern niedergeschlagen, angeschossen oder niedergestochen wurden. Am 10. Januar erfolgte dann eine 1. Stufe der Eskalation. Von einem Gericht wurden die \"3 Terroristen von Vasylkv\" schuldig gesprochen. Vor dem Gericht kam es zu Tumulten von Demonstranten, die versuchten, die Polizei am Abtransport zu hindern. Das Urteil wurde von den Demonstranten als Farze gesehen, insbesondere eingedenk der Tatsache, dass das Denkmal, welches die Terroridten zerstoeren wollten, schon einige Monate vorher von den Behoerden entfernt worden war. Am 16.1. stand im Parlament die Verabschiedung des Haushaltes an, weitere Themen standen nicht auf der Tagesordnung. Ploetzlich wurden eine Reihe von Gesetzen beschlossen, die die Buergerrrechte einschraenken sollten, Demonstranten kriminalisierten, das Internet zensurierten. Der Ausbruch der Gewalt danach war vorabsehbar.'}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "print('*** топ 3 найвіддаленіших коментарів ***')\n",
    "for i in arg_dists[:3]:\n",
    "    print(comments[i])\n",
    "\n",
    "print('\\n\\n *** топ 3 найближчих кометарів ***')\n",
    "for i in arg_dists[-3:]:\n",
    "    print(comments[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Завдання 3, 4\n",
    "Зробимо токенізацію та фільтрацію провокаційних сутностей за допомогою спейсі (для основних данних)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.base import TransformerMixin, BaseEstimator\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = read_comments(work_dir / 'junta.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label': 'trolling',\n",
       " 'author': 'Berlino10',\n",
       " 'text': 'dachten die Syrer anfangs auch, sie wurden fur mehr Freiheiten und einen kleinen Wandel demonstrieren und dann schaltete sich die internationale \"Diplomatie\" ein ;) Ja, ich behaupte, fur viele Politiker sind demonstrierende Menschen nur Werkzeuge. Alle skizzieren Bedrohungen, ob dies nun russische Hegemonialinteressen sind, wirtschaftliche Interessen des Westens. Die Klischees sind mittlerweile so tief verwurzelt und genau darum liest man in Medien so oft das Bild, dass die Ereignisse in der Ukraine fur Europa so unglaublich wichtig sind, aber was ist mit den einfachsten Grunden, fur Proteste und Demos? Ein bisschen mehr Freiheit. Ein bisschen weniger Korruption. Ein bisschen weniger \"Die da oben und wir hier unten\". Ein bisschen mehr Perspektive und weniger Zukunftsangste.Ob man diese Vorgange im Ubrigen Revolution nennen kann, das steht auf einem anderen Blatt.'}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Piscator76', 19),\n",
       " ('Berlino10', 18),\n",
       " ('Stetschkin', 16),\n",
       " ('Fremdhier', 15),\n",
       " ('Mandalore', 14),\n",
       " ('Pippin', 11),\n",
       " ('faktenfaktenfakten', 10),\n",
       " ('Waltraud Gundlach', 10),\n",
       " ('Heekhof', 9),\n",
       " ('Reverend Wicks Cherrycoke', 9)]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# підрахунок найактивніших авторів\n",
    "from collections import Counter\n",
    "author_counter = Counter(df.authors)\n",
    "author_counter.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Kiew, PER)  (Der Prasident der Ukraine, MISC)  \n",
      "(Aufstand, MISC)  (Orangenen Revolution, MISC)  \n",
      "(Revolution, MISC)  \n",
      "(deutschen, MISC)  \n",
      "(EU, ORG)  \n",
      "(Janukowitsch, MISC)  (EU, ORG)  (Ukrainer, MISC)  (Tee, PER)  (Zentrum Kiews, LOC)  \n",
      "(Maidan, LOC)  \n",
      "(EU-Abkommen, LOC)  \n",
      "(Janukowitsch, MISC)  \n",
      "(Meschigorja, MISC)  (Ukraine, LOC)  (ukrainisches, MISC)  \n",
      "(Janukowitsch, PER)  (London, LOC)  (Wien, LOC)  \n",
      "(Janukowitschs Sohn Alexander, PER)  (All-Ukrainische Entwicklungsbank, ORG)  \n",
      "(Janukowitsch, MISC)  \n",
      "(Parlamentswahlen 2013, MISC)  (Janukowitschs Partei, ORG)  \n",
      "(Ukraine, LOC)  \n",
      "(Ukrainer, LOC)  (Deutsche, MISC)  (Supermarkt, LOC)  (Autohaus, LOC)  \n",
      "(Orangene Revolution, MISC)  \n",
      "(Europa, LOC)  (Amerika, LOC)  (Facebook, MISC)  \n",
      "(Fu, MISC)  \n",
      "(ball-EM, MISC)  (Europa, LOC)  \n",
      "(sozialen, MISC)  \n",
      "(Twitter, MISC)  (Facebook, MISC)  (russischen, MISC)  \n",
      "(Organisation der Revolution, ORG)  (Kiew, LOC)  \n",
      "(Aufstand, MISC)  \n",
      "(Viktor Juschtschenko, PER)  (Ukrainer, MISC)  \n",
      "(Ukraine, LOC)  \n",
      "(Revolutionsdorfes, LOC)  (Ukraine, LOC)  \n",
      "(Russland, LOC)  (Holodomor, LOC)  \n",
      "(Ukrainer, MISC)  (Zeit, MISC)  (Stalins, PER)  (Ukrainer, MISC)  \n",
      "(Maidan, MISC)  \n",
      "(Swoboda-Anhanger, MISC)  (Sondereinsatzpolizisten, LOC)  \n",
      "(Ultras, LOC)  \n"
     ]
    }
   ],
   "source": [
    "from itertools import islice\n",
    "\n",
    "sents = islice(article.sents, 0, 50)\n",
    "\n",
    "# глянемо на сутності в перших 50 реченнях і їх типи, щоб знати що фільтрувати\n",
    "# типи сутностей можна подивитися в спейсі аннотейшнс\n",
    "for sent in sents:\n",
    "    for ent in sent.ents:\n",
    "        print(f'({ent.text.strip()}, {ent.label_})', end='  ')\n",
    "    if sent.ents:\n",
    "        print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# спостереження: Крим не знаходить, Київ в деяких місцях позначає як персону"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# леми + фільтрація, за бажання можна додавати інші типи сутнсостей чи конкретні слова\n",
    "\n",
    "ents_to_filter = ('LOC',)\n",
    "words_to_filter = ('Krim', 'krim', 'Kiew', 'kiew')\n",
    "\n",
    "def lemma_gpe(text, words_to_filter, ents_to_filter):\n",
    "    text = [t.lemma_ for t in nlp(text) if t.ent_type not in ents_to_filter]\n",
    "    text = [t for t in text if t not in words_to_filter]\n",
    "    return ' '.join(text)\n",
    "\n",
    "texts = [lemma_gpe(x, words_to_filter, ents_to_filter) for x in df.texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# будуємо тестову і тренувальну вибірки\n",
    "data_train, data_test, label_train, label_test = train_test_split(texts, df.labels, test_size=0.3, \n",
    "                                                                  stratify=df.labels, shuffle=True,\n",
    "                                                                  random_state=42)\n",
    "\n",
    "le = LabelEncoder()\n",
    "le.fit(df.labels)\n",
    "\n",
    "label_train = le.transform(label_train)\n",
    "label_test = le.transform(label_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['neutral', 'trolling'], dtype='<U8')"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseTextTransform(TransformerMixin):\n",
    "    \n",
    "    def fit(self, texts, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, texts, y=None):\n",
    "        texts = [self.transform_one(t) for t in texts]\n",
    "        return texts\n",
    "    \n",
    "    def transform_one(self, text):\n",
    "        raise NotImplementedError\n",
    "\n",
    "class TextCleaner(BaseTextTransform):\n",
    "    \n",
    "    def transform_one(self, text):\n",
    "        text = text.lower()\n",
    "        text = self.replace_numbers(text)\n",
    "        return text\n",
    "    \n",
    "    def replace_numbers(self, text):\n",
    "        return re.sub(r'\\d+', '000', text)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import regex as re\n",
    "\n",
    "# оскільки ми перед чим використали токенізацію спейсі, а потім з'єднали токени через пробіл, то зараз можемо просто зробити спліт по \"\\s+\"\n",
    "def my_tokenize(text):\n",
    "    return re.split(r'\\s+', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/igor/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Завдання 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_pipe = Pipeline([\n",
    "    ('cleaning', TextCleaner()),\n",
    "    ('counts', CountVectorizer(tokenizer=my_tokenize, stop_words=stopwords.words('german'))),\n",
    "])\n",
    "\n",
    "logit_pipe = Pipeline([\n",
    "    ('features', features_pipe),\n",
    "    ('logit', LogisticRegression()),\n",
    "])\n",
    "\n",
    "logit_hyper = {\n",
    "    'features__counts__analyzer': ['word', 'char'],\n",
    "    'features__counts__ngram_range': [(1, 1), (1, 2), (1, 3), (3, 4), (3, 5), (4, 5), (4, 6)],\n",
    "    'logit__C': [0.1, 1.0, 10],\n",
    "    'logit__class_weight': ['balanced']\n",
    "}\n",
    "\n",
    "logit_clf = GridSearchCV(logit_pipe, logit_hyper, scoring='f1', cv=3, refit=True, verbose=2, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 42 candidates, totalling 126 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:    9.8s\n",
      "[Parallel(n_jobs=-1)]: Done 126 out of 126 | elapsed:  1.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score 0.7329500489997781\n",
      "Best Params {'features__counts__analyzer': 'word', 'features__counts__ngram_range': (4, 5), 'logit__C': 0.1, 'logit__class_weight': 'balanced'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/igor/.pyenv/versions/prj-nlp-2019/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "logit_clf.fit(data_train, label_train)\n",
    "\n",
    "print('Best Score', logit_clf.best_score_)\n",
    "print('Best Params', logit_clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def general_report(model):\n",
    "    predict_test = model.predict(data_test)\n",
    "    report = classification_report(y_true=label_test, y_pred=predict_test)\n",
    "    print(report)\n",
    "    print('\\n')\n",
    "    \n",
    "    try:\n",
    "        weights = model.best_estimator_.__dict__['steps'][1][1].coef_[0]\n",
    "        ngrams = model.best_estimator_.__dict__['steps'][0][1].__dict__['steps'][1][1].get_feature_names()\n",
    "        ngrams_weights = sorted(zip(ngrams, weights), key=lambda x: -abs(x[1]))\n",
    "\n",
    "        for ng, w in ngrams_weights[:20]:\n",
    "            print(f'{ng:>20} : {w:.2f}')\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['neutral', 'trolling'], dtype='<U8')"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# мітки лейбл енкодера\n",
    "le.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.07      0.14       147\n",
      "           1       0.59      0.99      0.74       195\n",
      "\n",
      "   micro avg       0.60      0.60      0.60       342\n",
      "   macro avg       0.72      0.53      0.44       342\n",
      "weighted avg       0.70      0.60      0.48       342\n",
      "\n",
      "\n",
      "\n",
      "    ukraine gro ? te : -0.11\n",
      "  ? te vollig europa : -0.08\n",
      "? te vollig europa liegend : -0.08\n",
      "     gro ? te vollig : -0.08\n",
      "gro ? te vollig europa : -0.08\n",
      "te vollig europa liegend : -0.08\n",
      "te vollig europa liegend land : -0.08\n",
      "ukraine gro ? te vollig : -0.08\n",
      "vollig europa liegend land : -0.08\n",
      "     \" ukraine gro ? : -0.07\n",
      "  \" ukraine gro ? te : -0.07\n",
      "allerdings leute westdeutschland jahrzehntelang : 0.06\n",
      "allerdings leute westdeutschland jahrzehntelang verklickert : 0.06\n",
      "leute westdeutschland jahrzehntelang verklickert : 0.06\n",
      "leute westdeutschland jahrzehntelang verklickert . : 0.06\n",
      "monster allerdings leute westdeutschland : 0.06\n",
      "monster allerdings leute westdeutschland jahrzehntelang : 0.06\n",
      "russe monster allerdings leute : 0.06\n",
      "russe monster allerdings leute westdeutschland : 0.06\n",
      "westdeutschland jahrzehntelang verklickert . : 0.06\n"
     ]
    }
   ],
   "source": [
    "general_report(logit_clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Тепер побудуємо SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_pipe = Pipeline([\n",
    "    ('cleaning', TextCleaner()),\n",
    "    ('counts', CountVectorizer(tokenizer=my_tokenize, stop_words=stopwords.words('german'))),\n",
    "])\n",
    "\n",
    "svm_pipe = Pipeline([\n",
    "    ('features', features_pipe),\n",
    "    ('svm', SVC()),\n",
    "])\n",
    "\n",
    "svm_hyper = {\n",
    "    'features__counts__analyzer': ['word', 'char'],\n",
    "    'features__counts__ngram_range': [(1, 2), (1, 3), (3, 5), (4, 5), (4, 6)],\n",
    "    'svm__kernel': ['rbf'],\n",
    "    'svm__probability': [True],\n",
    "    'svm__class_weight': ['balanced'],\n",
    "    'svm__C': [1000]\n",
    "}\n",
    "\n",
    "svm_clf = GridSearchCV(svm_pipe, svm_hyper, scoring='f1', cv=3, refit=True, verbose=2, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 56 candidates, totalling 168 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:   35.4s\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:  7.6min\n",
      "[Parallel(n_jobs=-1)]: Done 168 out of 168 | elapsed:  9.5min finished\n",
      "/home/igor/.pyenv/versions/prj-nlp-2019/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score 0.7314285988485613\n",
      "Best Params {'features__counts__analyzer': 'word', 'features__counts__ngram_range': (4, 5), 'logit__C': 10}\n"
     ]
    }
   ],
   "source": [
    "svm_clf.fit(data_train, label_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score 0.7317602739267556\n",
      "Best Params {'features__counts__analyzer': 'word', 'features__counts__ngram_range': (4, 5), 'svm__C': 1000, 'svm__class_weight': 'balanced', 'svm__kernel': 'rbf', 'svm__probability': True}\n"
     ]
    }
   ],
   "source": [
    "print('Best Score', svm_clf.best_score_)\n",
    "print('Best Params', svm_clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.06      0.11       147\n",
      "           1       0.58      0.99      0.73       195\n",
      "\n",
      "   micro avg       0.59      0.59      0.59       342\n",
      "   macro avg       0.70      0.53      0.42       342\n",
      "weighted avg       0.68      0.59      0.47       342\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "general_report(svm_clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Післямова\n",
    "Як бачиш рекол на нейтральному класі дуже впав, скоріш за все це пов'язано з видаленням іменованих сутностей - спробуй поекспериментувати"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
